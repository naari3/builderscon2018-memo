今データセンターのサーバーには90以上のコアがある
　
これをmainとworkerに切り分けた理由
シンプルにしたかった
シングルスレッドなのでブロッキングの心配はいらない

envoy複雑性を欠きたい
まるでシングルスレッドのようにコードが書ける

イベントループ
ブロックするとよくない
モダンOSだとプログラミングにも対処できるのかと言うとそうでもない
ノンブロッキングだとしてもファイル書き込みだとよくッブロッキングされる
fileosで見てきたこと ッブロッキングが出るので問題kが有る
fileioフラッシュスレッドを作ってそこでロッキングをさせて、メインスレッドではブロックされないようにする
ブロックするとレイテンシが伸びて良くない

ここでは無限にスレッドを走らせられる
envoyでは数100もの

RCUろっきんぐぷりみてぃぶ　

ReadCopyUpdate
Readヘビーな環境の場合、ろっくすることなく
全てのワーカースレッドはイベントループ
休止期間
たとえばデータをアップデートできない→ロックできなくても良い
ReadWriteロッキングを実際にロッキングすることなくできる
もんだいなくスケールできる


Envoyのコアのひとつ
たとえばルートマネージャクラスタマネージャのなかのひとつ
メインスレッドで何かをやる、新しいルートチェックヘルスチェックなど
データの可用性は全てのスレッドで担保する
ほすとのじょうほうを使うがロックはしたくない、高速にしたいので
これはRCU的にはロードヘビー
ThreadLocalStorageというのはスロットのベクターになる

コンフィグの変更があったなど様々な理由がある


みんながコンテナ、BGデプロイをする
みんながしているわけではない
フルでのバイナリリロードをスレッドを落とさずにやりたい

デプロイモデルが2つ
k8s BG ローリング ホットリスタ０と
A→A'→となる
全部同じボックスでコネクションを落とさずにする

statではshared memoryリレーションでやる
あるゲージがある新しいenvoyのホットリスタート
古いプロセスを流し切る
シェアしてないと、前回のコネクションを切ってしまう
これはだめ、statに一貫性をもたせる
そのためにはこれをshared memoryに入れないといけない

新しいenvoyをあげる、linux上でやりとりがされる
いろいろちぇっく、プロセス立ち上げる
チェック→コネクションを流し切る

古いものが流しきって終了





